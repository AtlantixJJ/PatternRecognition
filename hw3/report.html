<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
  .markdown-body {
    box-sizing: border-box;
    min-width: 200px;
    max-width: 980px;
    margin: 0 auto;
    padding: 45px;
  }
  
  @media (max-width: 767px) {
    .markdown-body {
      padding: 15px;
    }
  }
  
  @font-face {
    font-family: octicons-link;
    src: url(data:font/woff;charset=utf-8;base64,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)
      format("woff");
  }
  
  .markdown-body {
    -ms-text-size-adjust: 100%;
    -webkit-text-size-adjust: 100%;
    line-height: 1.5;
    color: #24292e;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial,
      sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
    font-size: 16px;
    line-height: 1.5;
    word-wrap: break-word;
  }
  
  .markdown-body .pl-c {
    color: #6a737d;
  }
  
  .markdown-body .pl-c1,
  .markdown-body .pl-s .pl-v {
    color: #005cc5;
  }
  
  .markdown-body .pl-e,
  .markdown-body .pl-en {
    color: #6f42c1;
  }
  
  .markdown-body .pl-smi,
  .markdown-body .pl-s .pl-s1 {
    color: #24292e;
  }
  
  .markdown-body .pl-ent {
    color: #22863a;
  }
  
  .markdown-body .pl-k {
    color: #d73a49;
  }
  
  .markdown-body .pl-s,
  .markdown-body .pl-pds,
  .markdown-body .pl-s .pl-pse .pl-s1,
  .markdown-body .pl-sr,
  .markdown-body .pl-sr .pl-cce,
  .markdown-body .pl-sr .pl-sre,
  .markdown-body .pl-sr .pl-sra {
    color: #032f62;
  }
  
  .markdown-body .pl-v,
  .markdown-body .pl-smw {
    color: #e36209;
  }
  
  .markdown-body .pl-bu {
    color: #b31d28;
  }
  
  .markdown-body .pl-ii {
    color: #fafbfc;
    background-color: #b31d28;
  }
  
  .markdown-body .pl-c2 {
    color: #fafbfc;
    background-color: #d73a49;
  }
  
  .markdown-body .pl-c2::before {
    content: "^M";
  }
  
  .markdown-body .pl-sr .pl-cce {
    font-weight: bold;
    color: #22863a;
  }
  
  .markdown-body .pl-ml {
    color: #735c0f;
  }
  
  .markdown-body .pl-mh,
  .markdown-body .pl-mh .pl-en,
  .markdown-body .pl-ms {
    font-weight: bold;
    color: #005cc5;
  }
  
  .markdown-body .pl-mi {
    font-style: italic;
    color: #24292e;
  }
  
  .markdown-body .pl-mb {
    font-weight: bold;
    color: #24292e;
  }
  
  .markdown-body .pl-md {
    color: #b31d28;
    background-color: #ffeef0;
  }
  
  .markdown-body .pl-mi1 {
    color: #22863a;
    background-color: #f0fff4;
  }
  
  .markdown-body .pl-mc {
    color: #e36209;
    background-color: #ffebda;
  }
  
  .markdown-body .pl-mi2 {
    color: #f6f8fa;
    background-color: #005cc5;
  }
  
  .markdown-body .pl-mdr {
    font-weight: bold;
    color: #6f42c1;
  }
  
  .markdown-body .pl-ba {
    color: #586069;
  }
  
  .markdown-body .pl-sg {
    color: #959da5;
  }
  
  .markdown-body .pl-corl {
    text-decoration: underline;
    color: #032f62;
  }
  
  .markdown-body .octicon {
    display: inline-block;
    vertical-align: text-top;
    fill: currentColor;
  }
  
  .markdown-body a {
    background-color: transparent;
    -webkit-text-decoration-skip: objects;
  }
  
  .markdown-body a:active,
  .markdown-body a:hover {
    outline-width: 0;
  }
  
  .markdown-body strong {
    font-weight: inherit;
  }
  
  .markdown-body strong {
    font-weight: bolder;
  }
  
  .markdown-body h1 {
    font-size: 2em;
    margin: 0.67em 0;
  }
  
  .markdown-body img {
    border-style: none;
  }
  
  .markdown-body svg:not(:root) {
    overflow: hidden;
  }
  
  .markdown-body code,
  .markdown-body kbd,
  .markdown-body pre {
    font-family: monospace, monospace;
    font-size: 1em;
  }
  
  .markdown-body hr {
    box-sizing: content-box;
    height: 0;
    overflow: visible;
  }
  
  .markdown-body input {
    font: inherit;
    margin: 0;
  }
  
  .markdown-body input {
    overflow: visible;
  }
  
  .markdown-body [type="checkbox"] {
    box-sizing: border-box;
    padding: 0;
  }
  
  .markdown-body * {
    box-sizing: border-box;
  }
  
  .markdown-body input {
    font-family: inherit;
    font-size: inherit;
    line-height: inherit;
  }
  
  .markdown-body a {
    color: #0366d6;
    text-decoration: none;
  }
  
  .markdown-body a:hover {
    text-decoration: underline;
  }
  
  .markdown-body strong {
    font-weight: 600;
  }
  
  .markdown-body hr {
    height: 0;
    margin: 15px 0;
    overflow: hidden;
    background: transparent;
    border: 0;
    border-bottom: 1px solid #dfe2e5;
  }
  
  .markdown-body hr::before {
    display: table;
    content: "";
  }
  
  .markdown-body hr::after {
    display: table;
    clear: both;
    content: "";
  }
  
  .markdown-body table {
    border-spacing: 0;
    border-collapse: collapse;
  }
  
  .markdown-body td,
  .markdown-body th {
    padding: 0;
  }
  
  .markdown-body h1,
  .markdown-body h2,
  .markdown-body h3,
  .markdown-body h4,
  .markdown-body h5,
  .markdown-body h6 {
    margin-top: 0;
    margin-bottom: 0;
  }
  
  .markdown-body h1 {
    font-size: 32px;
    font-weight: 600;
  }
  
  .markdown-body h2 {
    font-size: 24px;
    font-weight: 600;
  }
  
  .markdown-body h3 {
    font-size: 20px;
    font-weight: 600;
  }
  
  .markdown-body h4 {
    font-size: 16px;
    font-weight: 600;
  }
  
  .markdown-body h5 {
    font-size: 14px;
    font-weight: 600;
  }
  
  .markdown-body h6 {
    font-size: 12px;
    font-weight: 600;
  }
  
  .markdown-body p {
    margin-top: 0;
    margin-bottom: 10px;
  }
  
  .markdown-body blockquote {
    margin: 0;
  }
  
  .markdown-body ul,
  .markdown-body ol {
    padding-left: 0;
    margin-top: 0;
    margin-bottom: 0;
  }
  
  .markdown-body ol ol,
  .markdown-body ul ol {
    list-style-type: lower-roman;
  }
  
  .markdown-body ul ul ol,
  .markdown-body ul ol ol,
  .markdown-body ol ul ol,
  .markdown-body ol ol ol {
    list-style-type: lower-alpha;
  }
  
  .markdown-body dd {
    margin-left: 0;
  }
  
  .markdown-body code {
    font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier,
      monospace;
    font-size: 12px;
  }
  
  .markdown-body pre {
    margin-top: 0;
    margin-bottom: 0;
    font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier,
      monospace;
    font-size: 12px;
  }
  
  .markdown-body .octicon {
    vertical-align: text-bottom;
  }
  
  .markdown-body .pl-0 {
    padding-left: 0 !important;
  }
  
  .markdown-body .pl-1 {
    padding-left: 4px !important;
  }
  
  .markdown-body .pl-2 {
    padding-left: 8px !important;
  }
  
  .markdown-body .pl-3 {
    padding-left: 16px !important;
  }
  
  .markdown-body .pl-4 {
    padding-left: 24px !important;
  }
  
  .markdown-body .pl-5 {
    padding-left: 32px !important;
  }
  
  .markdown-body .pl-6 {
    padding-left: 40px !important;
  }
  
  .markdown-body::before {
    display: table;
    content: "";
  }
  
  .markdown-body::after {
    display: table;
    clear: both;
    content: "";
  }
  
  .markdown-body > *:first-child {
    margin-top: 0 !important;
  }
  
  .markdown-body > *:last-child {
    margin-bottom: 0 !important;
  }
  
  .markdown-body a:not([href]) {
    color: inherit;
    text-decoration: none;
  }
  
  .markdown-body .anchor {
    float: left;
    padding-right: 4px;
    margin-left: -20px;
    line-height: 1;
  }
  
  .markdown-body .anchor:focus {
    outline: none;
  }
  
  .markdown-body p,
  .markdown-body blockquote,
  .markdown-body ul,
  .markdown-body ol,
  .markdown-body dl,
  .markdown-body table,
  .markdown-body pre {
    margin-top: 0;
    margin-bottom: 16px;
  }
  
  .markdown-body hr {
    height: 0.25em;
    padding: 0;
    margin: 24px 0;
    background-color: #e1e4e8;
    border: 0;
  }
  
  .markdown-body blockquote {
    padding: 0 1em;
    color: #6a737d;
    border-left: 0.25em solid #dfe2e5;
  }
  
  .markdown-body blockquote > :first-child {
    margin-top: 0;
  }
  
  .markdown-body blockquote > :last-child {
    margin-bottom: 0;
  }
  
  .markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font-size: 11px;
    line-height: 10px;
    color: #444d56;
    vertical-align: middle;
    background-color: #fafbfc;
    border: solid 1px #c6cbd1;
    border-bottom-color: #959da5;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #959da5;
  }
  
  .markdown-body h1,
  .markdown-body h2,
  .markdown-body h3,
  .markdown-body h4,
  .markdown-body h5,
  .markdown-body h6 {
    margin-top: 24px;
    margin-bottom: 16px;
    font-weight: 600;
    line-height: 1.25;
  }
  
  .markdown-body h1 .octicon-link,
  .markdown-body h2 .octicon-link,
  .markdown-body h3 .octicon-link,
  .markdown-body h4 .octicon-link,
  .markdown-body h5 .octicon-link,
  .markdown-body h6 .octicon-link {
    color: #1b1f23;
    vertical-align: middle;
    visibility: hidden;
  }
  
  .markdown-body h1:hover .anchor,
  .markdown-body h2:hover .anchor,
  .markdown-body h3:hover .anchor,
  .markdown-body h4:hover .anchor,
  .markdown-body h5:hover .anchor,
  .markdown-body h6:hover .anchor {
    text-decoration: none;
  }
  
  .markdown-body h1:hover .anchor .octicon-link,
  .markdown-body h2:hover .anchor .octicon-link,
  .markdown-body h3:hover .anchor .octicon-link,
  .markdown-body h4:hover .anchor .octicon-link,
  .markdown-body h5:hover .anchor .octicon-link,
  .markdown-body h6:hover .anchor .octicon-link {
    visibility: visible;
  }
  
  .markdown-body h1 {
    padding-bottom: 0.3em;
    font-size: 2em;
    border-bottom: 1px solid #eaecef;
  }
  
  .markdown-body h2 {
    padding-bottom: 0.3em;
    font-size: 1.5em;
    border-bottom: 1px solid #eaecef;
  }
  
  .markdown-body h3 {
    font-size: 1.25em;
  }
  
  .markdown-body h4 {
    font-size: 1em;
  }
  
  .markdown-body h5 {
    font-size: 0.875em;
  }
  
  .markdown-body h6 {
    font-size: 0.85em;
    color: #6a737d;
  }
  
  .markdown-body ul,
  .markdown-body ol {
    padding-left: 2em;
  }
  
  .markdown-body ul ul,
  .markdown-body ul ol,
  .markdown-body ol ol,
  .markdown-body ol ul {
    margin-top: 0;
    margin-bottom: 0;
  }
  
  .markdown-body li > p {
    margin-top: 16px;
  }
  
  .markdown-body li + li {
    margin-top: 0.25em;
  }
  
  .markdown-body dl {
    padding: 0;
  }
  
  .markdown-body dl dt {
    padding: 0;
    margin-top: 16px;
    font-size: 1em;
    font-style: italic;
    font-weight: 600;
  }
  
  .markdown-body dl dd {
    padding: 0 16px;
    margin-bottom: 16px;
  }
  
  .markdown-body table {
    display: block;
    width: 100%;
    overflow: auto;
  }
  
  .markdown-body table th {
    font-weight: 600;
  }
  
  .markdown-body table th,
  .markdown-body table td {
    padding: 6px 13px;
    border: 1px solid #dfe2e5;
  }
  
  .markdown-body table tr {
    background-color: #fff;
    border-top: 1px solid #c6cbd1;
  }
  
  .markdown-body table tr:nth-child(2n) {
    background-color: #f6f8fa;
  }
  
  .markdown-body img {
    max-width: 100%;
    box-sizing: content-box;
    background-color: #fff;
  }
  
  .markdown-body img[align="right"] {
    padding-left: 20px;
  }
  
  .markdown-body img[align="left"] {
    padding-right: 20px;
  }
  
  .markdown-body code {
    padding: 0;
    padding-top: 0.2em;
    padding-bottom: 0.2em;
    margin: 0;
    font-size: 85%;
    background-color: rgba(27, 31, 35, 0.05);
    border-radius: 3px;
  }
  
  .markdown-body code::before,
  .markdown-body code::after {
    letter-spacing: -0.2em;
    content: "\00a0";
  }
  
  .markdown-body pre {
    word-wrap: normal;
  }
  
  .markdown-body pre > code {
    padding: 0;
    margin: 0;
    font-size: 100%;
    word-break: normal;
    white-space: pre;
    background: transparent;
    border: 0;
  }
  
  .markdown-body .highlight {
    margin-bottom: 16px;
  }
  
  .markdown-body .highlight pre {
    margin-bottom: 0;
    word-break: normal;
  }
  
  .markdown-body .highlight pre,
  .markdown-body pre {
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f6f8fa;
    border-radius: 3px;
  }
  
  .markdown-body pre code {
    display: inline;
    max-width: auto;
    padding: 0;
    margin: 0;
    overflow: visible;
    line-height: inherit;
    word-wrap: normal;
    background-color: transparent;
    border: 0;
  }
  
  .markdown-body pre code::before,
  .markdown-body pre code::after {
    content: normal;
  }
  
  .markdown-body .full-commit .btn-outline:not(:disabled):hover {
    color: #005cc5;
    border-color: #005cc5;
  }
  
  .markdown-body kbd {
    display: inline-block;
    padding: 3px 5px;
    font: 11px "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier,
      monospace;
    line-height: 10px;
    color: #444d56;
    vertical-align: middle;
    background-color: #fafbfc;
    border: solid 1px #d1d5da;
    border-bottom-color: #c6cbd1;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 #c6cbd1;
  }
  
  .markdown-body :checked + .radio-label {
    position: relative;
    z-index: 1;
    border-color: #0366d6;
  }
  
  .markdown-body .task-list-item {
    list-style-type: none;
  }
  
  .markdown-body .task-list-item + .task-list-item {
    margin-top: 3px;
  }
  
  .markdown-body .task-list-item input {
    margin: 0 0.2em 0.25em -1.6em;
    vertical-align: middle;
  }
  
  .markdown-body hr {
    border-bottom-color: #eee;
  }
  </style>
</head>
<body>
<article class="markdown-body">
<h1 id="hw3-实验报告">HW3 实验报告</h1>
<p>2015011313 徐鉴劲 计54</p>
<h2 id="problem1">Problem1</h2>
<p>问题描述：给定一个数据集进行无监督学习，确定一个产生数据的分布。类别数量是通过假设预先确定的。</p>
<p>数据图(三类均等)</p>
<div class="figure">
<img src="fig/dataset_111.png" />

</div>
<h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h3>
<p>假设这个数据是由多个概率混合而成：<span class="math inline">\(P(x) = \sum P(x|\omega_i)P(\omega_i)\)</span>。</p>
<p>其中每一个概率假设为高斯分布：<span class="math inline">\(P(x|\omega_i) = \frac{1}{\sqrt{(2\pi)^d |\Sigma|}} e^{-\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu)}\)</span>.</p>
<p>它实际上是一个关于<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\Sigma\)</span>可导的函数，其中<span class="math inline">\(\mu\)</span>是N维向量，<span class="math inline">\(\Sigma\)</span>是<span class="math inline">\(N \times N\)</span>矩阵。</p>
<p>所以将它表示成一个函数的形式：<span class="math inline">\(P(x | \omega_i) = f(x; \mu, \Sigma)\)</span>。</p>
<p>那么整个概率分布就是<span class="math inline">\(P(x) = \sum t_i \mathcal{N}(x; \mu_i, \Sigma_i)\)</span>，其中<span class="math inline">\(t_i\)</span>是满足<span class="math inline">\(0 \le t_i \le 1\)</span>且加起来为1的标量。</p>
<p>构造损失函数<span class="math inline">\(l = - \sum_k lnP(x_k)\)</span>，然后我们可以对参数求导，进而进行优化。</p>
<h3 id="实现方式">实现方式</h3>
<p>由于求导数的步骤比较麻烦，我采用了tensorflow中的自动求导功能。</p>
<p>为了将上述表达式实现在tensorflow中，需要做以下必要的处理：</p>
<ol style="list-style-type: decimal">
<li><p>矩阵化<span class="math inline">\(l = - \sum_k lnP(x_k)\)</span>中的求和部分。因为tensorflow不支持挨个求和的操作。</p></li>
<li><p>将<span class="math inline">\(\Sigma\)</span>参数限制为正定矩阵。</p></li>
<li><p>将<span class="math inline">\(t_i\)</span>参数的限制完成。</p></li>
</ol>
<h4 id="矩阵化">矩阵化</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> lnp_x_mu_sigma(x, mu, sigma, t):
    res <span class="op">=</span> <span class="dv">0</span>
    N <span class="op">=</span> mu.get_shape().as_list()[<span class="dv">0</span>]

    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):
        m <span class="op">=</span> mu[i:i<span class="op">+</span><span class="dv">1</span>, :]
        s <span class="op">=</span> sigma[i, :, :]

        det <span class="op">=</span> tf.matrix_determinant(s)
        inv <span class="op">=</span> tf.matrix_inverse(s)
        n_sample <span class="op">=</span> tf.cast(tf.shape(x)[<span class="dv">0</span>], tf.float64)

        a1 <span class="op">=</span> tf.sqrt( (<span class="dv">2</span> <span class="op">*</span> np.pi) <span class="op">**</span> N <span class="op">*</span> det)
        a2 <span class="op">=</span>  <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> tf.reduce_sum(tf.matmul(x <span class="op">-</span> m, inv) <span class="op">*</span> (x <span class="op">-</span> m), axis<span class="op">=</span><span class="dv">1</span>)

        res <span class="op">+=</span> tf.exp(a2) <span class="op">/</span> a1 <span class="op">*</span> t[i]
    res <span class="op">=</span> tf.reduce_sum(tf.log(res))</code></pre></div>
<h4 id="正定化">正定化</h4>
<p>利用了<span class="math inline">\(A^T A\)</span>是正定对称矩阵的事实。</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">sigma <span class="op">=</span> tf.Variable(init_sigma)
psigma <span class="op">=</span> tf.matmul(sigma, sigma, transpose_a<span class="op">=</span><span class="va">True</span>)</code></pre></div>
<h4 id="t_i的限制"><span class="math inline">\(t_i\)</span>的限制</h4>
<p>将实数范围内的变量通过函数<span class="math inline">\(x^2+1\)</span>映射到<span class="math inline">\((1, +oo)\)</span>上，然后归一化。</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">t <span class="op">=</span> tf.Variable(np.ones((N,), dtype<span class="op">=</span><span class="st">&quot;float64&quot;</span>))
et <span class="op">=</span> (<span class="dv">1</span><span class="op">+</span>t<span class="op">*</span>t) <span class="op">/</span> tf.reduce_sum(<span class="dv">1</span><span class="op">+</span>t<span class="op">*</span>t)</code></pre></div>
<h4 id="吉布斯采样优化">吉布斯采样优化</h4>
<p>我发现同时优化t和<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\Sigma\)</span>容易导致t过早收敛到一个错误的直，所以我采用两步迭代优化：</p>
<p>在loss&gt;8000的时候只优化<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\Sigma\)</span>，然后在loss&lt;8000的时候交替优化<span class="math inline">\(\mu,\Sigma\)</span>，和t</p>
<h4 id="求导与优化器">求导与优化器</h4>
<p>最开始的时候我采用的是朴素的梯度下降法，但是学习率的设置是一个问题，所以我使用了一种自适应学习率算法：Adam.</p>
<p>然后我还对Adam的学习率进行了规划，根据不同loss的大小选择对应的学习率。</p>
<h3 id="实验结果">实验结果</h3>
<p>题目中涉及到的数据集一共有四个：</p>
<ol style="list-style-type: decimal">
<li><p>1000个数据点下，概率均等。</p></li>
<li><p>1000个数据点下，概率不均等。</p></li>
<li><p>300个数据点下，概率均等。</p></li>
<li><p>300个数据点下，概率不均等。</p></li>
</ol>
<p>但是题目中只要求做3个实验，于是我取了：</p>
<ol style="list-style-type: lower-alpha">
<li><p>1000个数据点下，概率均等。</p></li>
<li><p>1000个数据点下，概率不均等。</p></li>
<li><p>300个数据点下，概率均等。</p></li>
</ol>
<p>因为数据点很少的时候，概率是否均等并没有太大关系，因为本身数据的随机性就很大了。</p>
<p>对于每一个实验结果没有进行多次重复。</p>
<h4 id="训练loss图">训练loss图</h4>
<div class="figure">
<img src="fig/loss.png" />

</div>
<p>可以看到loss的下降并不是很平滑，这说明了MLE并不是凸优化，而且tf存在一定的数值不稳定</p>
<h4 id="参数估计结果a">参数估计结果（a)</h4>
<table>
<thead>
<tr class="header">
<th align="left">先验权重</th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(t_i\)</span></td>
<td align="left">0.39054</td>
<td align="left">0.33358</td>
<td align="left">0.27588</td>
</tr>
</tbody>
</table>
<p>先验权重与数据吻合，正确。</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\mu\)</span></th>
<th align="left">x</th>
<th align="left">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_1\)</span></td>
<td align="left">7.28943</td>
<td align="left">7.06694</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu_2\)</span></td>
<td align="left">15.00692</td>
<td align="left">1.01494</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_3\)</span></td>
<td align="left">0.89612</td>
<td align="left">1.01104</td>
</tr>
</tbody>
</table>
<p>结果与(7, 7), (15, 1), (1, 1)十分接近，剩下不准确的原因可能是数据的随机性与算法未收敛到最优解。</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">7.88187</td>
<td align="left">2.79020</td>
</tr>
<tr class="even">
<td align="left">2.79020</td>
<td align="left">1.87916</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">2.17459</td>
<td align="left">-0.10019</td>
</tr>
<tr class="odd">
<td align="left">-0.10019</td>
<td align="left">1.79766</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">11.56872</td>
<td align="left">0.11756</td>
</tr>
<tr class="even">
<td align="left">0.11756</td>
<td align="left">0.92613</td>
</tr>
</tbody>
</table>
<p>生成数据的<span class="math inline">\(\Sigma\)</span>如下</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">8</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">0</td>
<td align="left">2</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">12</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">0</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<p>他们十分接近，同样说明了估计的有效性。</p>
<h4 id="参数估计结果b">参数估计结果（b)</h4>
<table>
<thead>
<tr class="header">
<th align="left">先验权重</th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(t_i\)</span></td>
<td align="left">0.30055</td>
<td align="left">0.55747</td>
<td align="left">0.14198</td>
</tr>
</tbody>
</table>
<p>与设定的先验很接近。</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\mu\)</span></th>
<th align="left">x</th>
<th align="left">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_1\)</span></td>
<td align="left">6.88429</td>
<td align="left">6.95063</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu_2\)</span></td>
<td align="left">0.79475</td>
<td align="left">1.04674</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_3\)</span></td>
<td align="left">15.04197</td>
<td align="left">0.91565</td>
</tr>
</tbody>
</table>
<p>结果与(7, 7), (15, 1), (1, 1)十分接近，剩下不准确的原因可能是数据的随机性与算法未收敛到最优解。</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">7.62127</td>
<td align="left">2.50899</td>
</tr>
<tr class="even">
<td align="left">2.50899</td>
<td align="left">1.70573</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">10.92268</td>
<td align="left">-0.10753</td>
</tr>
<tr class="odd">
<td align="left">-0.10753</td>
<td align="left">1.01599</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">2.20195</td>
<td align="left">0.18426</td>
</tr>
<tr class="even">
<td align="left">0.18426</td>
<td align="left">2.11459</td>
</tr>
</tbody>
</table>
<p>生成数据的<span class="math inline">\(\Sigma\)</span>如下</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">8</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">12</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">0</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">0</td>
<td align="left">2</td>
</tr>
</tbody>
</table>
<p>有一定误差。</p>
<h4 id="参数估计结果c">参数估计结果（c)</h4>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\mu\)</span></th>
<th align="left">x</th>
<th align="left">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_1\)</span></td>
<td align="left">7.20120</td>
<td align="left">0.37176</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu_2\)</span></td>
<td align="left">9.39782</td>
<td align="left">1.55818</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_3\)</span></td>
<td align="left">6.40659</td>
<td align="left">6.78052</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">59.41734</td>
<td align="left">-5.46793</td>
</tr>
<tr class="even">
<td align="left">-5.46793</td>
<td align="left">1.70666</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">48.23648</td>
<td align="left">4.50168</td>
</tr>
<tr class="odd">
<td align="left">4.50168</td>
<td align="left">1.80242</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">7.60814</td>
<td align="left">2.79271</td>
</tr>
<tr class="even">
<td align="left">2.79271</td>
<td align="left">1.87219</td>
</tr>
</tbody>
</table>
<p>在只有300个数据点的情况下，所有参数的估计差距均很大。</p>
<h2 id="bayesian-estimation">Bayesian Estimation</h2>
<p>问题描述：给定了一个具有类别的数据集，估计产生它的高斯分布。</p>
<p>课上介绍了单元高斯分布建模参数，并学习<span class="math inline">\(\mu\)</span>的过程。</p>
<p>但是数据集产生分布中的<span class="math inline">\(\Sigma\)</span>并没有进行学习。</p>
<p>而且这道题中要求进行二维高斯分布建模。</p>
<h3 id="多元be理论基础">多元BE理论基础</h3>
<p>我们的目的是得到参数的后验概率。</p>
<p><span class="math inline">\(P(\theta | \mathcal{D}) = \alpha \Pi_k P(x_k | \theta) p(\theta)\)</span>.</p>
<p>其中<span class="math inline">\(P(x | \theta) \sim \mathcal{N}(x; \mu, \Sigma)\)</span>。</p>
<p><span class="math inline">\(p(\theta)\)</span>是一个先验假设，此处我们不知道任何情况，它是一个具有0均值和<span class="math inline">\(+oo\)</span>方差的正态分布函数，<span class="math inline">\(p(\theta_i) \sim \mathcal{N}(\theta_i; m_i, s_i^2)\)</span>，<span class="math inline">\(m_i=0\)</span>，<span class="math inline">\(s_i=+oo\)</span>。</p>
<p>所以<span class="math inline">\(P(\theta | \mathcal{D}) = \left [ \alpha \Pi_k \mathcal{N}(x_k; \mu, \Sigma) \right ] \left [ \Pi_i \mathcal{N}(\theta_i; m_i, s_i^2) \right ] = \left [ \alpha \Pi_k \mathcal{N}(x_k; \mu, \Sigma) \right ] \left [ \mathcal{N}(\theta_i; M m_i, M s_i^2) \right ]\)</span>.</p>
<p>其中M是参数的个数。因为参数的分布假设成一样的了。</p>
<p>对于前一项：<span class="math inline">\(\Pi_k \mathcal{N}(x_k; \mu, \Sigma)\)</span></p>
<p>=<span class="math inline">\(\Pi_k \frac{1}{\sqrt{(2 \pi)^d |\Sigma|}} e^{-\frac{1}{2} (x_k - \mu)^T \Sigma^{-1} (x_k - \mu)}\)</span></p>
<p>=<span class="math inline">\((\frac{1}{\sqrt{(2 \pi)^d |\Sigma|}})^N e^{-\frac{1}{2} \sum_k (x_k - \mu)^T \Sigma^{-1} (x_k - \mu)}\)</span></p>
<p>我们需要化简指数项：<span class="math inline">\(\sum_k (x_k - \mu)^T \Sigma^{-1} (x_k - \mu)\)</span></p>
<p>=<span class="math inline">\(\sum_k x_k^T \Sigma^{-1} x_k - x_k^T \Sigma^{-1} \mu - \mu^T \Sigma^{-1} x_k + \mu^T \Sigma^{-1} \mu\)</span></p>
<p>=<span class="math inline">\(\sum_k \left [ x_k^T \Sigma^{-1} x_k - 2 x_k^T \Sigma^{-1} \mu \right ] + N \mu^T \Sigma^{-1} \mu\)</span></p>
<p>首先我们以<span class="math inline">\(\mu\)</span>为主元进行整理：</p>
<p><span class="math inline">\(\sum_k (x_k - \mu)^T \Sigma^{-1} (x_k - \mu)\)</span></p>
<p>=<span class="math inline">\(N \mu^T \Sigma^{-1} \mu - 2(\sum_k x_k^T)\Sigma^{-1} \mu + \sum_k x_k^T \Sigma^{-1} x_k\)</span></p>
<p>=<span class="math inline">\((\mu - \frac{1}{N} \sum_k x_k)^T N\Sigma^{-1} (\mu - \frac{1}{N} \sum_k x_k) - \frac{1}{N} (\sum_k x_k)^T \Sigma^{-1} \sum_k x_k + \sum_k x_k^T \Sigma^{-1} x_k\)</span></p>
<p>所以：</p>
<p><span class="math inline">\(P(\mu | \mathcal{D}) = \alpha&#39; p(\theta) e^{-\frac{1}{2} (\mu - \frac{1}{N} \sum_k x_k)^T N\Sigma^{-1} (\mu - \frac{1}{N} \sum_k x_k)}\)</span></p>
<p>=<span class="math inline">\(\alpha&#39; p(\theta) \mathcal{N}(\frac{1}{N} \sum_k x_k, N\Sigma^{-1})\)</span></p>
<p>=<span class="math inline">\(\alpha&#39; \mathcal{N}(\theta_i; M m_i, M s_i^2) \mathcal{N}(\frac{1}{N} \sum_k x_k, N\Sigma^{-1})\)</span></p>
<p>=<span class="math inline">\(\alpha&#39; \mathcal{N}(\frac{1}{N} \sum_k x_k, \frac{\Sigma}{N})\)</span></p>
<p>然后我们对<span class="math inline">\(\Sigma\)</span>为主元进行整理。</p>
<p>设<span class="math inline">\((\Sigma^{-1})_{ij} = b_{ij}\)</span>，同理设<span class="math inline">\((x_k)_i = x_{ki}\)</span>，再令<span class="math inline">\(\sum_k x_k = c\)</span></p>
<p><span class="math inline">\(\sum_k (x_k - \mu)^T \Sigma^{-1} (x_k - \mu)\)</span></p>
<p>=<span class="math inline">\(\sum_k \sum_j \sum_i (x_{ki} - \mu_i) b_{ij} (x_{kj} - \mu_j)\)</span></p>
<p>=<span class="math inline">\(\sum_k \sum_j \sum_i b_{ij} (x_{ki}x_{kj} - x_{ki}\mu_j - x_{kj}\mu_i + \mu_i\mu_j)\)</span></p>
<p>=<span class="math inline">\(\sum_{ij} b_{ij} ( \sum_k x_{ki}x_{kj} - c_i \mu_j - c_j \mu_i + N \mu_i\mu_j )\)</span></p>
<p><span class="math inline">\(\sum_k x_{ki}x_{kj} = (X^T X)_{ij}\)</span>,</p>
<p><span class="math inline">\(c_i \mu_j = (c\mu^T)_{ij}\)</span>, <span class="math inline">\(c_j \mu_i = (c\mu^T)_{ji}\)</span>,</p>
<p><span class="math inline">\(\mu_i \mu_j = (\mu \mu^T)_{ij}\)</span></p>
<p>所以：</p>
<p><span class="math inline">\(\sum_k (x_k - \mu)^T \Sigma^{-1} (x_k - \mu)\)</span></p>
<p>=<span class="math inline">\(\sum_{ij} b_{ij} (X^T X + N \mu\mu^T - c\mu^T - \mu c^T )_{ij} = \sum_{ij} b_{ij} (X^T X + N \mu\mu^T - c\mu^T - \mu c^T + c c^T - c c^T )_{ij}\)</span></p>
<p>=<span class="math inline">\(\sum_{ij} \Sigma^{-1} \odot (X^T X - c c^T + \frac{1}{N}(N \mu - c)(N \mu - c)^T )_{ij}\)</span></p>
<p>将<span class="math inline">\(\sum_{ij}\)</span>从指数项目上拆解下来，可以化成:</p>
<p><span class="math inline">\(P(\Sigma) = \alpha&#39;&#39; \Pi_{ij} e^{-\frac{1}{2}\Sigma^{-1}_{ij}(X^T X - c c^T + \frac{1}{N}(N \mu - c)(N \mu - c)^T )_{ij}}\)</span></p>
<h3 id="实验结果-1">实验结果</h3>
<h4 id="参数估计结果a-1">参数估计结果（a)</h4>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\mu\)</span></th>
<th align="left">x</th>
<th align="left">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_1\)</span></td>
<td align="left">0.94192</td>
<td align="left">1.03805</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu_2\)</span></td>
<td align="left">7.00880</td>
<td align="left">6.92195</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_3\)</span></td>
<td align="left">15.05649</td>
<td align="left">1.01704</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">11.83856</td>
<td align="left">-0.33173</td>
</tr>
<tr class="even">
<td align="left">-0.33173</td>
<td align="left">0.99943</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">7.73065</td>
<td align="left">3.08681</td>
</tr>
<tr class="odd">
<td align="left">3.08681</td>
<td align="left">2.12755</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">1.83321</td>
<td align="left">-0.11916</td>
</tr>
<tr class="even">
<td align="left">-0.11916</td>
<td align="left">1.97818</td>
</tr>
</tbody>
</table>
<h4 id="参数估计结果b-1">参数估计结果(b)</h4>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\mu\)</span></th>
<th align="left">x</th>
<th align="left">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_1\)</span></td>
<td align="left">0.94192</td>
<td align="left">1.03805</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu_2\)</span></td>
<td align="left">7.00880</td>
<td align="left">6.92195</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_3\)</span></td>
<td align="left">15.05649</td>
<td align="left">1.01704</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">11.83856</td>
<td align="left">-0.33173</td>
</tr>
<tr class="even">
<td align="left">-0.33173</td>
<td align="left">0.99943</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">7.73065</td>
<td align="left">3.08681</td>
</tr>
<tr class="odd">
<td align="left">3.08681</td>
<td align="left">2.12755</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">1.83321</td>
<td align="left">-0.11916</td>
</tr>
<tr class="even">
<td align="left">-0.11916</td>
<td align="left">1.97818</td>
</tr>
</tbody>
</table>
<h4 id="参数估计结果c-1">参数估计结果(c)</h4>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\mu\)</span></th>
<th align="left">x</th>
<th align="left">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_1\)</span></td>
<td align="left">1.08155</td>
<td align="left">1.00883</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu_2\)</span></td>
<td align="left">7.21747</td>
<td align="left">7.19486</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu_3\)</span></td>
<td align="left">14.96565</td>
<td align="left">1.21260</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(\Sigma_0\)</span></th>
<th align="left"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">12.15760</td>
<td align="left">-0.11317</td>
</tr>
<tr class="even">
<td align="left">-0.11317</td>
<td align="left">0.97244</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\Sigma_1\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">8.02456</td>
<td align="left">3.13810</td>
</tr>
<tr class="odd">
<td align="left">3.13810</td>
<td align="left">1.99747</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\Sigma_2\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">1.89756</td>
<td align="left">0.04821</td>
</tr>
<tr class="even">
<td align="left">0.04821</td>
<td align="left">1.80511</td>
</tr>
</tbody>
</table>
<h3 id="实验结果对比">实验结果对比</h3>
<p>BE在大、小数据量上表现都不错，但是它是一个有监督的方法。</p>
<p>MLE在大数据集上表现不错，在小数据集上误差较大，其优点在于是基本无监督的，只用设置一个类的数量，和KNN是类似的。</p>
<h2 id="problem-2-be">Problem 2: BE</h2>
<h3 id="a">(a)</h3>
<p><span class="math inline">\(P(D|\theta) = P(x_1,...,x_n|\theta) = \Pi_i P(x_i|\theta)\)</span></p>
<p>=<span class="math inline">\(\Pi_i \Pi_j \theta_i^{x_{ij}} (1 - \theta_i)^{1 - x_{ij}}\)</span></p>
<p>=<span class="math inline">\(\Pi_i \theta_i^{\sum_j x_{ij}} (1 - \theta_i)^{\sum_j (1 - x_{ij})}\)</span></p>
<p>=<span class="math inline">\(\Pi_i \theta_i^{s_i} (1 - \theta_i)^{n - s_j}\)</span></p>
<h3 id="b">(b)</h3>
<p><span class="math inline">\(P(\theta|D) = \frac{P(D|\theta)P(\theta)}{\int_0^1 P(D|\theta)P(\theta)d\theta}\)</span></p>
<p>因为<span class="math inline">\(P(\theta)\)</span>是均匀分布，所以分母中的<span class="math inline">\(\theta\)</span>可以提出来</p>
<p><span class="math inline">\(P(\theta|D) = \frac{P(D|\theta)}{\int_0^1 P(D|\theta) d\theta}\)</span></p>
<p>=<span class="math inline">\(\frac{\Pi_i \theta_i^{s_i} (1 - \theta_i)^{n - s_j}}{\int_0^1 \Pi_i \theta_i^{s_i} (1 - \theta_i)^{n - s_j}d\theta}\)</span></p>
<p>=<span class="math inline">\(\Pi_i \frac{(n + 1)!}{s_i! (n-s_i)!} \theta_i^{s_i} (1 - \theta_i)^{n - s_j}\)</span></p>
<h3 id="c">(c)</h3>
<p>When n=1 and d=1, x = 0 or 1</p>
<p><span class="math inline">\(P(\theta|D) = P(\theta|x)\)</span> = <span class="math inline">\(\frac{2}{x! (1-x)!} \theta^{x} (1 - \theta)^{1 - x}\)</span></p>
<p>=<span class="math inline">\(2 \theta^{x} (1 - \theta)^{1 - x}\)</span></p>
<p>Thus,</p>
<p><span class="math inline">\(P(\theta|x=0) = 2 (1 - \theta)\)</span></p>
<p><span class="math inline">\(P(\theta|x=1) = 2 \theta\)</span></p>
<p>The figure below shows the distribution</p>
<div class="figure">
<img src="fig/prob2.png" />

</div>
<h3 id="d">(d)</h3>
<p><span class="math inline">\(P(x|D)\)</span> is the classification confidence.</p>
<p><span class="math inline">\(P(x|D) = \int_0^1 P(x|\theta) P(\theta|D) d\theta\)</span></p>
<p>=<span class="math inline">\(\int_0^1 \Pi_i \theta_i^{x_i} (1 - \theta_i) ^ {1 - x_i} \frac{(n + 1)!}{s_i! (n-s_i)!} \theta_i^{s_i} (1 - \theta_i)^{n - s_i} d\theta\)</span></p>
<p>=<span class="math inline">\(\left [ \Pi_i \frac{(n + 1)!}{s_i! (n-s_i)!} \right ] \int_0^1 \Pi_i \theta_i^{x_i + s_i} (1 - \theta_i)^{1 + n - x_i - s_i} d\theta\)</span></p>
<p>As every <span class="math inline">\(\theta_i\)</span> is independent with each other, so the integration can be completely one by one</p>
<p>=<span class="math inline">\(\left [ \Pi_i \frac{(n + 1)!}{s_i! (n-s_i)!} \right ] \Pi_i \int_0^1 \theta_i^{x_i + s_i} (1 - \theta_i)^{1 + n - x_i - s_i} d\theta_i\)</span></p>
<p>=<span class="math inline">\(\Pi_i \frac{(n + 1)!}{s_i! (n-s_i)!} \frac{(x_i + s_i)!(1 + n - x_i - s_i)!}{(n + 2)!}\)</span></p>
<p>=<span class="math inline">\(\Pi_i [\frac{s_i + 1}{n+2}]^{x_i} [\frac{n+1-s_i}{n+2}]^{1 - x_i}\)</span></p>
<p>=<span class="math inline">\(\Pi_i [\frac{s_i + 1}{n+2}]^{x_i} [1 - \frac{s_i + 1}{n+2}]^{1 - x_i}\)</span></p>
<h3 id="e">(e)</h3>
<p>If we view <span class="math inline">\(P(x|D)\)</span> as some distribution obtained by <span class="math inline">\(P(x|\hat \theta)\)</span>, we can see from the formulae <span class="math inline">\(\Pi_i [\frac{s_i + 1}{n+2}]^{x_i} [1 - \frac{s_i + 1}{n+2}]^{1 - x_i}\)</span> that <span class="math inline">\(\hat \theta = \frac{s_i + 1}{n+2}\)</span>. In this way <span class="math inline">\(P(x|D) = \Pi_i \hat \theta_i^{x_i} (1 - \hat \theta_i) ^{1 - x_i}\)</span>.</p>
<p>However if you use an empirical estimation that each class probability is its frequency statistics, then we should obtain <span class="math inline">\(\theta_i = \frac{s_i}{n}\)</span>, which is different than the estimation of BE.</p>
<h2 id="problem-3-hmm">Problem 3: HMM</h2>
<h3 id="a-1">(a)</h3>
<p>Let transition matrix be <span class="math inline">\(a_{ij} = P(x_{t+1} = j|x_t = i)\)</span>.</p>
<p>And suppose A, B, C, D = 1, 2, 3, 4.</p>
<p>Take the statistics of the training data:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\omega_1\)</span></li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(P(x_{t+1} / x_t, \omega_1)\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=1\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=2\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=3\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(x_t=1\)</span></td>
<td align="left">0.23529</td>
<td align="left">0.47059</td>
<td align="left">0.17647</td>
<td align="left">0.11765</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x_t=2\)</span></td>
<td align="left">0.25000</td>
<td align="left">0.20000</td>
<td align="left">0.40000</td>
<td align="left">0.15000</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(x_t=3\)</span></td>
<td align="left">0.00000</td>
<td align="left">0.31250</td>
<td align="left">0.25000</td>
<td align="left">0.43750</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x_t=4\)</span></td>
<td align="left">0.00000</td>
<td align="left">0.11111</td>
<td align="left">0.22222</td>
<td align="left">0.66667</td>
</tr>
</tbody>
</table>
<p>Prior:</p>
<table>
<thead>
<tr class="header">
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.14516</td>
<td align="left">0.29032</td>
<td align="left">0.27419</td>
<td align="left">0.29032</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\omega_2\)</span></li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(P(x_{t+1} / x_t, \omega_2)\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=1\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=2\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=3\)</span></th>
<th align="left"><span class="math inline">\(x_{t+1}=4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(x_t=1\)</span></td>
<td align="left">0.57143</td>
<td align="left">0.21429</td>
<td align="left">0.07143</td>
<td align="left">0.14286</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x_t=2\)</span></td>
<td align="left">0.44444</td>
<td align="left">0.27778</td>
<td align="left">0.16667</td>
<td align="left">0.11111</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(x_t=3\)</span></td>
<td align="left">0.21429</td>
<td align="left">0.35714</td>
<td align="left">0.14286</td>
<td align="left">0.28571</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x_t=4\)</span></td>
<td align="left">0.17391</td>
<td align="left">0.13043</td>
<td align="left">0.26087</td>
<td align="left">0.43478</td>
</tr>
</tbody>
</table>
<p>Prior:</p>
<table>
<thead>
<tr class="header">
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.14516</td>
<td align="left">0.29032</td>
<td align="left">0.27419</td>
<td align="left">0.29032</td>
</tr>
</tbody>
</table>
<h3 id="b-1">(b)</h3>
<p>Let <span class="math inline">\(s\)</span> denote the sequence and <span class="math inline">\(c_i\)</span> be its i-th element. Use minimum error probability classification:</p>
<p>If <span class="math inline">\(P(s | \omega_1) \gt P(s | \omega_2)\)</span> then decide <span class="math inline">\(\omega_1\)</span>, otherwise decide <span class="math inline">\(\omega_2\)</span>.</p>
<p><span class="math inline">\(P(s | \omega) = P(x_1,...,x_n | \omega) = P(x_1=c_1) \Pi_{i=2} P(x_{i+1} = c_{i+1} | x_{i} = c_i, \omega)\)</span>.</p>
<p>To avoid underflow, use log-probability:</p>
<p><span class="math inline">\(J = -lnP(s | \omega) = \sum -ln P(x_{i+1} = c_{i+1} | x_{i} = c_i, \omega) - lnP(x_1=c_1)\)</span></p>
<p>Choose the smaller one.</p>
<p>Classification result:</p>
<table>
<thead>
<tr class="header">
<th align="left">1: ABBBCDDD</th>
<th align="left">2: DADBCBAA</th>
<th align="left">3: CDCBABA</th>
<th align="left">4: ADBBBCD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2</td>
<td align="left">1</td>
<td align="left">2</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<h3 id="c-1">(c)</h3>
<p>The classification process is plot as the figure below:</p>
<table>
<thead>
<tr class="header">
<th align="left">Probability of each product factor</th>
<th align="left">Probability of prefix string</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><img src="fig/prob3_1.png" /></td>
<td align="left"><img src="fig/prob3_2.png" /></td>
</tr>
</tbody>
</table>
<p>We can see that the same sequence will obtain different <code>step probability</code> at each step w.r.t. to different category.</p>
<p>Note that changing prior will not affect other <code>step probabilities</code>, so change the prior will make the log probability shift up-and-down as a whole.</p>
<p>Using original prior, we have:</p>
<p><span class="math inline">\(J_1 = J_1 + lnP(x_0 = c_0 | \omega_1) - lnP(x_0 = c_0 | \omega_1) = \hat J_1 - lnP(x_0 = c_0 | \omega_1)\)</span></p>
<p>and</p>
<p><span class="math inline">\(J_2 = J_2 + lnP(x_0 = c_0 | \omega_2) - lnP(x_0 = c_0 | \omega_2) = \hat J_2 - lnP(x_0 = c_0 | \omega_2)\)</span></p>
<p>subtract them:</p>
<p><span class="math inline">\(\Delta = \hat J_1 - \hat J_2 + lnP(x_0 = c_0 | \omega_2) - lnP(x_0 = c_0 | \omega_1)\)</span></p>
<p>To make two category output the same log probility based on a different prior, we have:</p>
<p><span class="math inline">\(\Delta&#39; = \hat J_1 - \hat J_2 + ln P_2 - ln P_1 = 0\)</span></p>
<p>This leads to</p>
<p><span class="math inline">\(ln P_1 - ln P_2 = -lnP(x_0 = c_0 | \omega_2) + lnP(x_0 = c_0 | \omega_1) + \Delta\)</span></p>
<p>As long as new prior <span class="math inline">\(P_1\)</span> and <span class="math inline">\(P_2\)</span> satisty this equation, the two category’s probability will be the same.</p>
<p>Suppose that category 1’s prior remains the same, now we can get an exact solution of category 2’s new prior.</p>
<p><span class="math inline">\(P_2 = exp( lnP(x_0 = c_0 | \omega_1) + \Delta )\)</span>, in which <span class="math inline">\(\Delta = J_1 - J_2\)</span>.</p>
<p>Now the classification process looks like</p>
<div class="figure">
<img src="fig/prob3_3.png" />

</div>
<p>From the figure we confirm that this two category have the same output probability.</p>
<h2 id="运行代码">运行代码</h2>
<p>第一题：</p>
<p>python prob1.py</p>
<p>有可能因为初始化太过极端，造成计算溢出（inf），此时重新运行一遍，问题一般就没有了。</p>
<p>其他题目：</p>
<pre><code>python prob2.py
python prob3.py</code></pre>
</article>
</body>
</html>
